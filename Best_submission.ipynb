{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d7XX7yaeBoMC"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ryAim0JRToN2",
    "outputId": "cba5ea4f-2718-4fb6-9507-ed9e6540f1a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rdkit in c:\\users\\rohit\\anaconda3\\lib\\site-packages (2022.9.4)\n",
      "Requirement already satisfied: numpy in c:\\users\\rohit\\anaconda3\\lib\\site-packages (from rdkit) (1.20.3)\n",
      "Requirement already satisfied: Pillow in c:\\users\\rohit\\anaconda3\\lib\\site-packages (from rdkit) (8.4.0)\n",
      "Requirement already satisfied: Boruta in c:\\users\\rohit\\anaconda3\\lib\\site-packages (0.3)\n",
      "Requirement already satisfied: scikit-learn>=0.17.1 in c:\\users\\rohit\\anaconda3\\lib\\site-packages (from Boruta) (1.2.2)\n",
      "Requirement already satisfied: numpy>=1.10.4 in c:\\users\\rohit\\anaconda3\\lib\\site-packages (from Boruta) (1.20.3)\n",
      "Requirement already satisfied: scipy>=0.17.0 in c:\\users\\rohit\\anaconda3\\lib\\site-packages (from Boruta) (1.7.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\rohit\\anaconda3\\lib\\site-packages (from scikit-learn>=0.17.1->Boruta) (2.2.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\rohit\\anaconda3\\lib\\site-packages (from scikit-learn>=0.17.1->Boruta) (1.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install rdkit\n",
    "!pip install Boruta\n",
    "\n",
    "\n",
    "from boruta import BorutaPy\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import Descriptors\n",
    "from rdkit.ML.Descriptors import MoleculeDescriptors\n",
    "from rdkit.Chem import MACCSkeys\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "\n",
    "from sklearn.metrics import f1_score, recall_score\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lccUps1M4lzA"
   },
   "outputs": [],
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4dmdcmf-Brow"
   },
   "source": [
    "# Preprocessing and pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "dHI-241UUPcl"
   },
   "outputs": [],
   "source": [
    "train_data_url = \"https://raw.githubusercontent.com/RohithOfRivia/SMILES-Toxicity-Prediction/main/Data/train_II.csv\"\n",
    "test_data_url = \"https://raw.githubusercontent.com/RohithOfRivia/SMILES-Toxicity-Prediction/main/Data/test_II.csv\"\n",
    "\n",
    "df = pd.read_csv(train_data_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "mF1xLYWXUQPa"
   },
   "outputs": [],
   "source": [
    "#transforming each compound into their canonical SMILES format. Optional.\n",
    "def canonicalSmiles(smile):\n",
    "    try:\n",
    "        return Chem.MolToSmiles(Chem.MolFromSmiles(smile))\n",
    "    except:\n",
    "        return(Chem.MolToSmiles(Chem.MolFromSmiles(\"[Na+].[Na+].F[Si--](F)(F)(F)(F)F\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "kqnkzT-bUQn6"
   },
   "outputs": [],
   "source": [
    "#Reads data and split up the given features\n",
    "class FileReadTransform(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    #training and test data are slightly different, hence passing optional test param\n",
    "    def transform(self, X, test=False):\n",
    "        \n",
    "        try:\n",
    "          # if test == False:\n",
    "            X['SMILES'] = X['Id'].apply(lambda x: x.split(';')[0])\n",
    "            X['assay'] = X['Id'].apply(lambda x: x.split(';')[1])\n",
    "        \n",
    "        except KeyError:\n",
    "            X['SMILES'] = X['x'].apply(lambda x: x.split(';')[0])\n",
    "            X['assay'] = X['x'].apply(lambda x: x.split(';')[1])\n",
    "          \n",
    "        print(\"FileReadTransform done\")\n",
    "        \n",
    "        #correct smiles for this compound found through https://www.molport.com/shop/index\n",
    "        #X[\"SMILES\"] = X[\"SMILES\"].replace({\"F[Si-2](F)(F)(F)(F)F.[Na+].[Na+]\":\"[Na+].[Na+].F[Si--](F)(F)(F)(F)F\"})\n",
    "        \n",
    "        #Deleting invalid compound from the data\n",
    "        X = X.loc[X.SMILES != \"F[Si-2](F)(F)(F)(F)F.[Na+].[Na+]\"]\n",
    "        return X\n",
    "    \n",
    "#Converts each SMILES value to its respective canonical SMILES \n",
    "class CanonicalGenerator(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X['SMILES'] = X['SMILES'].apply(canonicalSmiles)\n",
    "        print(\"CanonicalGenerator done\")\n",
    "        return X\n",
    "\n",
    "\n",
    "#Generate fingerprints for all compounds\n",
    "class FingerprintGenerator(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "          #tracks each unique compound and its fingerprints\n",
    "          tracker = []\n",
    "          fps = []\n",
    "          assays = []\n",
    "          unique = len(X['SMILES'].unique())\n",
    "          counter = 0\n",
    "\n",
    "          for index, columns in X[[\"SMILES\", \"assay\"]].iterrows():\n",
    "\n",
    "              #skip if already in tracker\n",
    "              if columns[0] in tracker:\n",
    "                  continue\n",
    "\n",
    "              #append each unique compound and theer respective fingerprints\n",
    "              else:\n",
    "                  tracker.append(columns[0])\n",
    "                  assays.append(columns[1])\n",
    "\n",
    "                  mol = Chem.MolFromSmiles(columns[0])\n",
    "                  fp = AllChem.GetMorganFingerprintAsBitVect(mol, 2, nBits=256)\n",
    "                  fps.append(fp.ToList())\n",
    "\n",
    "                  counter += 1\n",
    "\n",
    "                  # print(f\"compound {counter}/{unique}...\n",
    "\n",
    "          #Combining all compounds, assays and fingerprints into one dataframe \n",
    "          cols = a = [\"x\" + str(i) for i in range (1, 257)]\n",
    "          smiles_df = pd.DataFrame(columns=['SMILES'], data=tracker)\n",
    "          fingerprints = pd.DataFrame(columns=cols, data=fps)\n",
    "\n",
    "          df = pd.concat([smiles_df, fingerprints], axis=1)\n",
    "\n",
    "          print(\"FingerprintGenerator done\")\n",
    "          return pd.merge(X, df, on='SMILES') \n",
    "\n",
    "#Fingerprint generation for MACCS Keys\n",
    "class FingerprintGeneratorM(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "      \n",
    "          #tracks each unique compound and its fingerprints\n",
    "          tracker = []\n",
    "          fps = []\n",
    "          assays = []\n",
    "          unique = len(X['SMILES'].unique())\n",
    "          counter = 0\n",
    "\n",
    "          for index, columns in X[[\"SMILES\", \"assay\"]].iterrows():\n",
    "\n",
    "              #skip if already in tracker\n",
    "              if columns[0] in tracker:\n",
    "                  continue\n",
    "\n",
    "              #append each unique compound and thier respective fingerprints\n",
    "              else:\n",
    "                  \n",
    "\n",
    "                  tracker.append(columns[0])\n",
    "                  assays.append(columns[1])\n",
    "\n",
    "                  mol = Chem.MolFromSmiles(columns[0])\n",
    "                  fp = MACCSkeys.GenMACCSKeys(mol)\n",
    "                  fps.append(fp.ToList())\n",
    "\n",
    "                  counter += 1\n",
    "\n",
    "                  # print(f\"compound {counter}/{unique}...\n",
    "\n",
    "          #Combining all compounds, assays and fingerprints into one dataframe \n",
    "          cols = a = [\"x\" + str(i) for i in range (1, 168)]\n",
    "          smiles_df = pd.DataFrame(columns=['SMILES'], data=tracker)\n",
    "          fingerprints = pd.DataFrame(columns=cols, data=fps)\n",
    "\n",
    "          df = pd.concat([smiles_df, fingerprints], axis=1)\n",
    "\n",
    "          print(\"FingerprintGenerator done\")\n",
    "          return pd.merge(X, df, on='SMILES') \n",
    "\n",
    "\n",
    "#Feature reduction with variance threshold \n",
    "class VarianceThresh(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, thresh=.8):\n",
    "      \n",
    "      #Looks to columns to determine whether X is training or testing data \n",
    "      cols = X.columns\n",
    "      if 'x' in cols:\n",
    "        temp_df = X.drop(columns=[\"x\", \"assay\", \"SMILES\"])\n",
    "        cols = [\"x\", \"assay\", \"SMILES\"]\n",
    "      else:\n",
    "        temp_df = X.drop(columns=[\"Id\", \"Expected\",\"assay\", \"SMILES\"])\n",
    "        cols = [\"Id\", \"Expected\",\"assay\", \"SMILES\"]\n",
    "\n",
    "      #Selecting features based on the variance threshold\n",
    "      selector = VarianceThreshold(threshold=(thresh * (1 - thresh))) \n",
    "      selector.fit(temp_df)\n",
    "\n",
    "      #This line transforms the data while keeping the column names \n",
    "      temp_df = temp_df.loc[:, selector.get_support()]\n",
    "\n",
    "      #Attaching the ids, assays, smiles etc. that is still required for model\n",
    "      return pd.concat([X[cols], temp_df], axis=1) , selector\n",
    "\n",
    "\n",
    "#Scale descriptors (Not used in this notebook)\n",
    "class Scaler(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "      return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "      scaler = StandardScaler()\n",
    "\n",
    "      if 'Id' in X.columns:\n",
    "        temp_df = X.drop(columns=[\"Id\", \"Expected\", \"assay\", \"SMILES\"])\n",
    "        cols = [\"Id\", \"Expected\",\"assay\", \"SMILES\"]\n",
    "\n",
    "        X_scaled = pd.DataFrame(scaler.fit_transform(temp_df), columns=temp_df.columns)\n",
    "        X = pd.concat([X[cols].reset_index(drop=True), X_scaled], axis=1)\n",
    "          \n",
    "        return X\n",
    "\n",
    "      else:\n",
    "        temp_df = X.drop(columns=[\"x\", \"assay\", \"SMILES\"])\n",
    "        cols = [\"x\", \"assay\", \"SMILES\"]\n",
    "\n",
    "        X_scaled = pd.DataFrame(scaler.fit_transform(temp_df), columns=temp_df.columns)\n",
    "        X = pd.concat([X[cols].reset_index(drop=True), X_scaled], axis=1)\n",
    "\n",
    "        return X\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bArk50ghju_F"
   },
   "source": [
    "# Generating descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "hEDljdsOhxja"
   },
   "outputs": [],
   "source": [
    "class DescriptorGenerator(BaseEstimator, TransformerMixin):\n",
    "\n",
    "  def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "  def transform(self, X):\n",
    "    #Initializing descriptor calculator\n",
    "    calc = MoleculeDescriptors.MolecularDescriptorCalculator([x[0] for x in Descriptors._descList])\n",
    "    desc_names = calc.GetDescriptorNames()\n",
    "\n",
    "    #Tracking each unique compound and generating descriptors \n",
    "    tracker = []\n",
    "    descriptors = []\n",
    "    for compound in X['SMILES']:\n",
    "\n",
    "      if compound in tracker:\n",
    "        continue\n",
    "\n",
    "      else:\n",
    "        tracker.append(compound)\n",
    "\n",
    "        mol = Chem.MolFromSmiles(compound)\n",
    "        current_descriptors = calc.CalcDescriptors(mol)\n",
    "        descriptors.append(current_descriptors)\n",
    "\n",
    "    # Combining X, SMILES, and generated descriptors \n",
    "    df = pd.DataFrame(descriptors,columns=desc_names)\n",
    "    temp_df = pd.DataFrame(tracker, columns=[\"SMILES\"])\n",
    "    df = pd.concat([df, temp_df], axis=1)\n",
    "\n",
    "    print(\"DescriptorGenerator done\")\n",
    "    return pd.merge(X, df, on='SMILES')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eeZP1h5mMb8W"
   },
   "source": [
    "# Create Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BSzN3tVUjrd3",
    "outputId": "cca18489-2048-4eae-8564-3a6237a26d83"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FileReadTransform done\n",
      "CanonicalGenerator done\n",
      "FingerprintGenerator done\n"
     ]
    }
   ],
   "source": [
    "feature_generation_pipeline = Pipeline(steps=[\n",
    "    ('read', FileReadTransform()),\n",
    "     ('canon', CanonicalGenerator()),\n",
    "     ('fpr', FingerprintGenerator()),\n",
    "     ('desc', DescriptorGenerator())\n",
    "     ])\n",
    "\n",
    "df_processed = feature_generation_pipeline.fit_transform(df)\n",
    "test_processed = feature_generation_pipeline.fit_transform(pd.read_csv(test_data_url))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZNYwNjbtCGnD"
   },
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TgFazc2wpV7n"
   },
   "outputs": [],
   "source": [
    "#Isolating the chemical descriptors for feature selection\n",
    "descriptors = pd.concat([df_processed[['Id','SMILES','assay', 'Expected']], df_processed[df_processed.columns[-208:]]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ym1AEXHphN_k",
    "outputId": "9741b829-2c3f-4ff6-ad8e-d3fd6929626c"
   },
   "outputs": [],
   "source": [
    "len(descriptors.columns[4:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RW4XjzgrYCOH",
    "outputId": "9e4f91cf-1f1c-4115-8d01-36d9d009a7de"
   },
   "outputs": [],
   "source": [
    "#Checking for NANs \n",
    "descriptors.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SR1lQ--GpWBw"
   },
   "outputs": [],
   "source": [
    "#Removing all columns which have NAN values\n",
    "descriptors2 = descriptors.drop(columns=['BCUT2D_MWHI', 'BCUT2D_MWLOW', 'BCUT2D_CHGHI', 'BCUT2D_CHGLO', 'BCUT2D_LOGPHI', 'BCUT2D_LOGPLOW',\n",
    "                      'BCUT2D_MRHI', 'BCUT2D_MRLOW'])\n",
    "descriptors2 = descriptors2.dropna()\n",
    "\n",
    "X = descriptors2.drop(['Id','SMILES','Expected'], axis=1)\n",
    "\n",
    "\n",
    "y = descriptors2[['Expected']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fAF1gqh5e-nk"
   },
   "outputs": [],
   "source": [
    "#Removing all columns which have NAN values\n",
    "X['assay'] = X['assay'].astype(\"int64\")\n",
    "\n",
    "#Features selected from BorutaPy\n",
    "boruta_features2 = ['HeavyAtomMolWt','MaxPartialCharge','MinAbsPartialCharge','BertzCT','Chi1','Chi1n','Chi2v','Chi3n','Chi3v','Chi4v','LabuteASA','PEOE_VSA3','SMR_VSA6','SMR_VSA7','EState_VSA8','VSA_EState2','VSA_EState4','HeavyAtomCount','NumAromaticCarbocycles','MolLogP','MolMR','fr_Ar_OH','fr_COO','fr_COO2','fr_C_O','fr_C_O_noCOO','fr_amide','fr_benzene','fr_phenol','fr_phenol_noOrthoHbond','fr_sulfonamd','fr_thiazole','fr_thiophene','fr_urea','assay']\n",
    "\n",
    "#Splitting data for training and validation. Mapping expected values from 2 to 1 because XGBoost does not support it for binary classification\n",
    "X_train, X_test, y_train, y_test = train_test_split(X[boruta_features2], y['Expected'].map({2:0, 1:1}), test_size=0.2, random_state=0, stratify=y['Expected'].map({2:0, 1:1}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "id": "OQcC_ccJi133",
    "outputId": "f8a0ac7c-eee3-42e9-ba0a-5e0dfc83a96a"
   },
   "outputs": [],
   "source": [
    "''' Optional to run this. Gives a list of features that pass the test as the output. \n",
    "The variable declaredboruta_features2 is a saved version of the output when the code was run for the best submission.\n",
    "Output may vary slightly if executed again'''\n",
    "\n",
    "# model = XGBClassifier(max_depth=6, learning_rate=0.01, n_estimators=600, colsample_bytree=0.3)\n",
    "\n",
    "# boruta_features = []\n",
    "\n",
    "# # let's initialize Boruta\n",
    "# feat_selector = BorutaPy(\n",
    "#     verbose=2,\n",
    "#     estimator=model,\n",
    "#     n_estimators='auto',\n",
    "#     max_iter=10  # number of iterations to perform\n",
    "# )\n",
    "\n",
    "# # train Boruta\n",
    "# # N.B.: X and y must be numpy arrays\n",
    "# feat_selector.fit(np.array(X_train), np.array(y_train))\n",
    "\n",
    "# # print support and ranking for each feature\n",
    "# print(\"\\n------Support and Ranking for each feature------\")\n",
    "# for i in range(len(feat_selector.support_)):\n",
    "#     if feat_selector.support_[i]:\n",
    "#         boruta_features.append(X_train.columns[i])\n",
    "#         print(\"Passes the test: \", X_train.columns[i],\n",
    "#               \" - Ranking: \", feat_selector.ranking_[i])\n",
    "#     else:\n",
    "#         print(\"Doesn't pass the test: \",\n",
    "#               X_train.columns[i], \" - Ranking: \", feat_selector.ranking_[i])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hxLjjzK3q1vN"
   },
   "source": [
    "# Training and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zG9MP6_XenIT"
   },
   "outputs": [],
   "source": [
    "#This method trains the model with the training data and then prints the f1 score by using predictions from the holdout data\n",
    "def train_model(xtrain, xtest, ytrain, ytest):\n",
    "  model = XGBClassifier(seed = 20, max_depth=10, n_estimators=700 )\n",
    "  model.fit(xtrain, ytrain)\n",
    "\n",
    "  predictions = model.predict(xtest)\n",
    "  print(f\"F1 Score of model: {f1_score(predictions, ytest)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K4FvsaAjgVEa",
    "outputId": "2efaec33-fa51-496e-b0f1-d5cb3552d9dd"
   },
   "outputs": [],
   "source": [
    "train_model(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 248
    },
    "id": "p-bLdz0yqcKo",
    "outputId": "6e98002e-474f-4708-9d37-ac0467b0a3a1"
   },
   "outputs": [],
   "source": [
    "#Now training with the entire dataset to make predictions on the test set\n",
    "\n",
    "descriptors2['assay'] = descriptors2['assay'].astype('int64') \n",
    "model = XGBClassifier(seed = 20, max_depth=10, n_estimators=700 )\n",
    "model.fit(descriptors2[boruta_features2], y['Expected'].map({2:0, 1:1}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u14WlDKcq_LE"
   },
   "outputs": [],
   "source": [
    "# Final predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UVJN6w9se-fZ",
    "outputId": "78451bd9-5086-46ff-dcc0-7f8030b449a0"
   },
   "outputs": [],
   "source": [
    "#Changing assayID to int\n",
    "test_processed['assay'] = test_processed['assay'].astype('int64')\n",
    "\n",
    "#Making predicitons with the model\n",
    "test_preds = model.predict(test_processed[boruta_features2])\n",
    "test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T9cJEQpLe-cp",
    "outputId": "64e5e3b5-e128-44a3-d723-8d601cc5321d"
   },
   "outputs": [],
   "source": [
    "#Checking predictions for posititve and negative valeus\n",
    "np.unique(test_preds, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Predicitons for kaggle submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "LgvQmjWsrRd3",
    "outputId": "fd1a76e8-462b-4bb8-f0af-b70fa149be8d"
   },
   "outputs": [],
   "source": [
    "#Converting the predictions into a dataframe\n",
    "res = pd.DataFrame({})\n",
    "res['Id'] = test_processed['x']\n",
    "res['Predicted'] = test_preds\n",
    "\n",
    "#Mapping expected values back to 2 and 1 \n",
    "res['Predicted'] = res['Predicted'].map({0:2, 1:1})\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For saving predictions as csv in JUPYTER\n",
    "res.to_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "0k7RPfkVrRXf",
    "outputId": "97d45044-0c87-46e0-f38c-960de5294afb"
   },
   "outputs": [],
   "source": [
    "#ONLY FOR GOOGLE COLLAB Downloading the csv for submission to kaggle\n",
    "# from google.colab import files\n",
    "\n",
    "# res.to_csv('28-03-23-2.csv', encoding = 'utf-8-sig', index=False) \n",
    "# files.download('28-03-23-2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "THZzszKyrRU8",
    "outputId": "578149ef-37a6-4bfe-c70b-0a83b2e8068c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-dc4ceff0-1d86-4527-add7-a21531a07a34\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CC1=CC(=C(C=C1)C(C)(C)C)O;1682</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CC1=CC(=C(C=C1)C(C)(C)C)O;2451</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CC1=CC(=C(C=C1)C(C)(C)C)O;2442</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CC1=CC(=C(C=C1)C(C)(C)C)O;32</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CC1=CC(=C(C=C1)C(C)(C)C)O;1382</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10989</th>\n",
       "      <td>CC(=CC(=O)C)C;1856</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10990</th>\n",
       "      <td>CCCCCCCCCC[N+](C)(C)CC1=CC=CC=C1.[Cl-];1848</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10991</th>\n",
       "      <td>CC1=C(C(=O)N(N1C)C2=CC=CC=C2)N(C)CS(=O)(=O)[O-...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10992</th>\n",
       "      <td>COC1=CC=CC(=C1)C=O;2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10993</th>\n",
       "      <td>CN1CC[C@]23[C@@H]4[C@H]1CC5=C2C(=C(C=C5)OC)O[C...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10994 rows Ã— 2 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dc4ceff0-1d86-4527-add7-a21531a07a34')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-dc4ceff0-1d86-4527-add7-a21531a07a34 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-dc4ceff0-1d86-4527-add7-a21531a07a34');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                                      Id  Predicted\n",
       "0                         CC1=CC(=C(C=C1)C(C)(C)C)O;1682          2\n",
       "1                         CC1=CC(=C(C=C1)C(C)(C)C)O;2451          2\n",
       "2                         CC1=CC(=C(C=C1)C(C)(C)C)O;2442          1\n",
       "3                           CC1=CC(=C(C=C1)C(C)(C)C)O;32          2\n",
       "4                         CC1=CC(=C(C=C1)C(C)(C)C)O;1382          2\n",
       "...                                                  ...        ...\n",
       "10989                                 CC(=CC(=O)C)C;1856          2\n",
       "10990        CCCCCCCCCC[N+](C)(C)CC1=CC=CC=C1.[Cl-];1848          1\n",
       "10991  CC1=C(C(=O)N(N1C)C2=CC=CC=C2)N(C)CS(=O)(=O)[O-...          2\n",
       "10992                               COC1=CC=CC(=C1)C=O;2          2\n",
       "10993  CN1CC[C@]23[C@@H]4[C@H]1CC5=C2C(=C(C=C5)OC)O[C...          2\n",
       "\n",
       "[10994 rows x 2 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "d7d5tcAn8SGl"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "d7XX7yaeBoMC",
    "4dmdcmf-Brow",
    "bArk50ghju_F",
    "eeZP1h5mMb8W"
   ],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
